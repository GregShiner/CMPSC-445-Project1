{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install dependencies and download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt\n",
    "#!curl -l -o data.csv \"https://phl.carto.com/api/v2/sql?q=SELECT+*,+ST_Y(the_geom)+AS+lat,+ST_X(the_geom)+AS+lng+FROM+opa_properties_public&filename=opa_properties_public&format=csv&skipfields=cartodb_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29786/1507164070.py:1: DtypeWarning: Columns (5,13,22,26,31,54,55,68,70,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582937, 82)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_geom</th>\n",
       "      <th>the_geom_webmercator</th>\n",
       "      <th>assessment_date</th>\n",
       "      <th>basements</th>\n",
       "      <th>beginning_point</th>\n",
       "      <th>book_and_page</th>\n",
       "      <th>building_code</th>\n",
       "      <th>building_code_description</th>\n",
       "      <th>category_code</th>\n",
       "      <th>category_code_description</th>\n",
       "      <th>...</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_built_estimate</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>zoning</th>\n",
       "      <th>pin</th>\n",
       "      <th>building_code_new</th>\n",
       "      <th>building_code_description_new</th>\n",
       "      <th>objectid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101000020E6100000288FB7AD4BC452C0C6E4F1E75A01...</td>\n",
       "      <td>0101000020110F00002693FA5D94E05FC1EE7D5D356691...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120' NW EADOM ST</td>\n",
       "      <td>987458.0</td>\n",
       "      <td>RB</td>\n",
       "      <td>NON PD PKG LOT COMMERCIAL</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19137.0</td>\n",
       "      <td>IRMX</td>\n",
       "      <td>1001189957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143301</td>\n",
       "      <td>40.010587</td>\n",
       "      <td>-75.067119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101000020E610000015F6916732CB52C0D4B37C0242FE...</td>\n",
       "      <td>0101000020110F0000F30438544DEC5FC1AAE24928F78D...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273' N OF NORRIS ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SR</td>\n",
       "      <td>VACANT LAND RESIDE &lt; ACRE</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19121.0</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001505175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143302</td>\n",
       "      <td>39.986389</td>\n",
       "      <td>-75.174951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101000020E610000066AC299B48CA52C053CA1DF46CFD...</td>\n",
       "      <td>0101000020110F00004ACDE132C0EA5FC17F6F06010B8D...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263' 8\" N COLUMBIA AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U50</td>\n",
       "      <td>ROW CONV/APT 3 STY MASON</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTI FAMILY</td>\n",
       "      <td>...</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19121.0</td>\n",
       "      <td>RM1</td>\n",
       "      <td>1001622123</td>\n",
       "      <td>22</td>\n",
       "      <td>ROW TYPICAL</td>\n",
       "      <td>433143303</td>\n",
       "      <td>39.979887</td>\n",
       "      <td>-75.160682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101000020E6100000000000000000F87F000000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,115.962' S PATTISON AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>VACANT LAND RESIDE ACRE+</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001319180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101000020E61000000C5CFE385BC452C0E38B05E75601...</td>\n",
       "      <td>0101000020110F0000F7332EC5AEE05FC1240EE0C46191...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEC SCATTERGOOD TO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>NON PD PKG LOT COMMERCIAL</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19137.0</td>\n",
       "      <td>IRMX</td>\n",
       "      <td>1001189938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143305</td>\n",
       "      <td>40.010465</td>\n",
       "      <td>-75.068068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            the_geom  \\\n",
       "0  0101000020E6100000288FB7AD4BC452C0C6E4F1E75A01...   \n",
       "1  0101000020E610000015F6916732CB52C0D4B37C0242FE...   \n",
       "2  0101000020E610000066AC299B48CA52C053CA1DF46CFD...   \n",
       "3  0101000020E6100000000000000000F87F000000000000...   \n",
       "4  0101000020E61000000C5CFE385BC452C0E38B05E75601...   \n",
       "\n",
       "                                the_geom_webmercator assessment_date  \\\n",
       "0  0101000020110F00002693FA5D94E05FC1EE7D5D356691...      2022-05-24   \n",
       "1  0101000020110F0000F30438544DEC5FC1AAE24928F78D...      2022-05-24   \n",
       "2  0101000020110F00004ACDE132C0EA5FC17F6F06010B8D...      2022-05-24   \n",
       "3                                                NaN      2022-05-24   \n",
       "4  0101000020110F0000F7332EC5AEE05FC1240EE0C46191...      2022-05-24   \n",
       "\n",
       "  basements            beginning_point book_and_page building_code  \\\n",
       "0       NaN           120' NW EADOM ST      987458.0         RB      \n",
       "1       NaN        273' N OF NORRIS ST           NaN         SR      \n",
       "2       NaN     263' 8\" N COLUMBIA AVE           NaN         U50     \n",
       "3       NaN  1,115.962' S PATTISON AVE           NaN         SS      \n",
       "4       NaN         NEC SCATTERGOOD TO           NaN         RB      \n",
       "\n",
       "   building_code_description  category_code category_code_description  ...  \\\n",
       "0  NON PD PKG LOT COMMERCIAL              6               VACANT LAND  ...   \n",
       "1  VACANT LAND RESIDE < ACRE              6               VACANT LAND  ...   \n",
       "2   ROW CONV/APT 3 STY MASON              2              MULTI FAMILY  ...   \n",
       "3   VACANT LAND RESIDE ACRE+              6               VACANT LAND  ...   \n",
       "4  NON PD PKG LOT COMMERCIAL              6               VACANT LAND  ...   \n",
       "\n",
       "   year_built year_built_estimate  zip_code zoning         pin  \\\n",
       "0         NaN                 NaN   19137.0   IRMX  1001189957   \n",
       "1         NaN                 NaN   19121.0   RSA5  1001505175   \n",
       "2      1890.0                 NaN   19121.0    RM1  1001622123   \n",
       "3         NaN                 NaN       NaN    NaN  1001319180   \n",
       "4         NaN                 NaN   19137.0   IRMX  1001189938   \n",
       "\n",
       "   building_code_new  building_code_description_new   objectid        lat  \\\n",
       "0                NaN                            NaN  433143301  40.010587   \n",
       "1                NaN                            NaN  433143302  39.986389   \n",
       "2                 22                    ROW TYPICAL  433143303  39.979887   \n",
       "3                NaN                            NaN  433143304        NaN   \n",
       "4                NaN                            NaN  433143305  40.010465   \n",
       "\n",
       "         lng  \n",
       "0 -75.067119  \n",
       "1 -75.174951  \n",
       "2 -75.160682  \n",
       "3        NaN  \n",
       "4 -75.068068  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['the_geom', 'the_geom_webmercator', 'assessment_date', 'basements',\n",
       "       'beginning_point', 'book_and_page', 'building_code',\n",
       "       'building_code_description', 'category_code',\n",
       "       'category_code_description', 'census_tract', 'central_air',\n",
       "       'cross_reference', 'date_exterior_condition', 'depth',\n",
       "       'exempt_building', 'exempt_land', 'exterior_condition', 'fireplaces',\n",
       "       'frontage', 'fuel', 'garage_spaces', 'garage_type',\n",
       "       'general_construction', 'geographic_ward', 'homestead_exemption',\n",
       "       'house_extension', 'house_number', 'interior_condition', 'location',\n",
       "       'mailing_address_1', 'mailing_address_2', 'mailing_care_of',\n",
       "       'mailing_city_state', 'mailing_street', 'mailing_zip', 'market_value',\n",
       "       'market_value_date', 'number_of_bathrooms', 'number_of_bedrooms',\n",
       "       'number_of_rooms', 'number_stories', 'off_street_open',\n",
       "       'other_building', 'owner_1', 'owner_2', 'parcel_number', 'parcel_shape',\n",
       "       'quality_grade', 'recording_date', 'registry_number', 'sale_date',\n",
       "       'sale_price', 'separate_utilities', 'sewer', 'site_type', 'state_code',\n",
       "       'street_code', 'street_designation', 'street_direction', 'street_name',\n",
       "       'suffix', 'taxable_building', 'taxable_land', 'topography',\n",
       "       'total_area', 'total_livable_area', 'type_heater', 'unfinished', 'unit',\n",
       "       'utility', 'view_type', 'year_built', 'year_built_estimate', 'zip_code',\n",
       "       'zoning', 'pin', 'building_code_new', 'building_code_description_new',\n",
       "       'objectid', 'lat', 'lng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see all of the columns available in the dataset. Many of these columns are not really necesary. For example, geographical data such as street addresses are not very useful because they don't contain any categorical or numerical data that can be easily consumed by a linear regression mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_REMOVE = \"\"\"\n",
    "the_geom\n",
    "the_geom_webmercator\n",
    "beginning_point\n",
    "book_and_page\n",
    "building_code_description\n",
    "category_code_description\n",
    "cross_reference\n",
    "geographic_ward\n",
    "house_number\n",
    "location\n",
    "mailing_address_1\n",
    "mailing_address_2\n",
    "mailing_care_of\n",
    "mailing_city_state\n",
    "mailing_street\n",
    "mailing_zip\n",
    "other_building\n",
    "owner_1\n",
    "owner_2\n",
    "parcel_number\n",
    "registry_number\n",
    "state_code\n",
    "street_code\n",
    "street_designation\n",
    "street_direction\n",
    "street_name\n",
    "suffix\n",
    "assessment_date\n",
    "recording_date\n",
    "sale_date\n",
    "pin\n",
    "zip_code\n",
    "parcel_shape\n",
    "quality_grade\n",
    "building_code\n",
    "building_code_new\n",
    "building_code_description_new\n",
    "objectid\n",
    "unit\n",
    "\"\"\"\n",
    "df_first_column_drop = df.drop(columns=COLUMNS_TO_REMOVE.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "df_first_column_drop.to_csv('data_first_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note about this dataset is that this data is for all types of properties in Philadelphia. Since we are only interested in housing data, we will filter this data to only be for housing type properties. This is accomplished by filtering for properties with a category code of 1 (single family), 2 (multi family), or 3 (mixed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_code</th>\n",
       "      <th>category_code_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>SINGLE FAMILY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72657</th>\n",
       "      <td>1</td>\n",
       "      <td>Single Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MULTI FAMILY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103077</th>\n",
       "      <td>2</td>\n",
       "      <td>Multi Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>MIXED USE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103887</th>\n",
       "      <td>3</td>\n",
       "      <td>Mixed Use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103634</th>\n",
       "      <td>4</td>\n",
       "      <td>Commercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105777</th>\n",
       "      <td>5</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5</td>\n",
       "      <td>INDUSTRIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99480</th>\n",
       "      <td>6</td>\n",
       "      <td>Vacant Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>7</td>\n",
       "      <td>GARAGE - COMMERCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>8</td>\n",
       "      <td>GARAGE - RESIDENTIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6285</th>\n",
       "      <td>9</td>\n",
       "      <td>HOTEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>10</td>\n",
       "      <td>OFFICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>11</td>\n",
       "      <td>SPECIAL PURPOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>12</td>\n",
       "      <td>VACANT LAND - NON-RESIDENTIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>13</td>\n",
       "      <td>VACANT LAND - RESIDENTIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>14</td>\n",
       "      <td>APARTMENTS  &gt; 4 UNITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>15</td>\n",
       "      <td>RETAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23535</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category_code      category_code_description\n",
       "11                  1                  SINGLE FAMILY\n",
       "72657               1                  Single Family\n",
       "2                   2                   MULTI FAMILY\n",
       "103077              2                   Multi Family\n",
       "6                   3                      MIXED USE\n",
       "103887              3                      Mixed Use\n",
       "5                   4                     COMMERCIAL\n",
       "103634              4                     Commercial\n",
       "105777              5                     Industrial\n",
       "248                 5                     INDUSTRIAL\n",
       "99480               6                    Vacant Land\n",
       "0                   6                    VACANT LAND\n",
       "1342                7            GARAGE - COMMERCIAL\n",
       "3271                8           GARAGE - RESIDENTIAL\n",
       "6285                9                          HOTEL\n",
       "1340               10                        OFFICES\n",
       "5701               11                SPECIAL PURPOSE\n",
       "527                12  VACANT LAND - NON-RESIDENTIAL\n",
       "202                13      VACANT LAND - RESIDENTIAL\n",
       "459                14          APARTMENTS  > 4 UNITS\n",
       "23130              15                         RETAIL\n",
       "23535              16                            NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all unique values of (category_code, category_code_description)\n",
    "df[['category_code', 'category_code_description']].drop_duplicates().sort_values(by='category_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(582937, 43)\n",
      "(503907, 43)\n"
     ]
    }
   ],
   "source": [
    "# Print number of data points\n",
    "print(df_first_column_drop.shape)\n",
    "# Filter category-type to 1, or 2\n",
    "df_first_column_drop = df_first_column_drop[df_first_column_drop['category_code'] <= 2]\n",
    "# Print number of data points\n",
    "print(df_first_column_drop.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed some of the columns, lets see what we are left with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basements                   object\n",
       "category_code                int64\n",
       "census_tract               float64\n",
       "central_air                 object\n",
       "date_exterior_condition     object\n",
       "depth                      float64\n",
       "exempt_building            float64\n",
       "exempt_land                float64\n",
       "exterior_condition         float64\n",
       "fireplaces                 float64\n",
       "frontage                   float64\n",
       "fuel                        object\n",
       "garage_spaces              float64\n",
       "garage_type                 object\n",
       "general_construction        object\n",
       "homestead_exemption          int64\n",
       "house_extension             object\n",
       "interior_condition         float64\n",
       "market_value               float64\n",
       "market_value_date          float64\n",
       "number_of_bathrooms        float64\n",
       "number_of_bedrooms         float64\n",
       "number_of_rooms            float64\n",
       "number_stories             float64\n",
       "off_street_open            float64\n",
       "sale_price                 float64\n",
       "separate_utilities          object\n",
       "sewer                       object\n",
       "site_type                   object\n",
       "taxable_building           float64\n",
       "taxable_land               float64\n",
       "topography                  object\n",
       "total_area                 float64\n",
       "total_livable_area         float64\n",
       "type_heater                 object\n",
       "unfinished                  object\n",
       "utility                     object\n",
       "view_type                   object\n",
       "year_built                 float64\n",
       "year_built_estimate         object\n",
       "zoning                      object\n",
       "lat                        float64\n",
       "lng                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_column_drop.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a lot of columns. It is very likely that many more of these will get dropped for the following reasons:\n",
    "1. Too many missing values\n",
    "2. Too many unique values\n",
    "3. Not enough correlation with the target variable\n",
    "\n",
    "Let's start by dealing with the first case: too many missing values. We will check this by counting the number of missing values in each column and sorting by this number.\n",
    "\n",
    "There are also a few columns that seem to have a default value put in them instead of being left blank. Lets also change these default values to na, so they can be counted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "df_first_column_drop['depth'] = df_first_column_drop['depth'].replace(0, np.nan)\n",
    "df_first_column_drop['total_area'] = df_first_column_drop['total_area'].replace(0, np.nan)\n",
    "df_first_column_drop['total_livable_area'] = df_first_column_drop['total_livable_area'].replace(0, np.nan)\n",
    "df_first_column_drop['year_built'] = df_first_column_drop['year_built'].replace(0, np.nan)\n",
    "df_first_column_drop['sale_price'] = df_first_column_drop['sale_price'].replace(1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         missing_values  percentage_missing\n",
      "market_value_date                503907            1.000000\n",
      "unfinished                       503844            0.999875\n",
      "utility                          503772            0.999732\n",
      "site_type                        501863            0.995944\n",
      "date_exterior_condition          501462            0.995148\n",
      "sewer                            490034            0.972469\n",
      "number_of_rooms                  489868            0.972140\n",
      "house_extension                  489308            0.971028\n",
      "separate_utilities               488822            0.970064\n",
      "garage_type                      481716            0.955962\n",
      "fuel                             456444            0.905810\n",
      "central_air                      211179            0.419083\n",
      "type_heater                      203555            0.403954\n",
      "basements                        174364            0.346024\n",
      "sale_price                       131445            0.260852\n",
      "year_built_estimate               94314            0.187165\n",
      "depth                             34709            0.068880\n",
      "total_area                        32821            0.065133\n",
      "topography                        32339            0.064177\n",
      "general_construction              15954            0.031661\n",
      "garage_spaces                      8248            0.016368\n",
      "fireplaces                         6963            0.013818\n",
      "number_of_bathrooms                6665            0.013227\n",
      "off_street_open                    4751            0.009428\n",
      "number_of_bedrooms                 3458            0.006862\n",
      "interior_condition                 3339            0.006626\n",
      "number_stories                     3323            0.006594\n",
      "exterior_condition                 3238            0.006426\n",
      "frontage                           3149            0.006249\n",
      "view_type                          2857            0.005670\n",
      "zoning                             1177            0.002336\n",
      "total_livable_area                  852            0.001691\n",
      "year_built                          621            0.001232\n",
      "census_tract                         23            0.000046\n",
      "lat                                  22            0.000044\n",
      "lng                                  22            0.000044\n",
      "taxable_building                     20            0.000040\n",
      "market_value                         19            0.000038\n",
      "taxable_land                         19            0.000038\n",
      "exempt_land                          19            0.000038\n",
      "exempt_building                      19            0.000038\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We still have a lot of columns. It is very likely that many more of these will get dropped for the following reasons:\n",
    "1. Too many missing values\n",
    "2. Too many unique values\n",
    "3. Not enough correlation with the target variable\n",
    "\n",
    "Let's start by dealing withe the first case: too many missing values. We will check this by counting the number of missing values in each column and sorting by this number.\n",
    "\"\"\"\n",
    "#print(df_first_column_drop.isna().sum().sort_values(ascending=False))\n",
    "# Print the number of missing values and the percentage of missing values\n",
    "missing_values = df_first_column_drop.isna().sum().sort_values(ascending=False)\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values = pd.DataFrame(missing_values, columns=['missing_values'])\n",
    "missing_values['percentage_missing'] = missing_values['missing_values'] / len(df_first_column_drop)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some of these pieces of missing data won't be that big of a deal because we can either fill or impute the data. We can also drop rows with missing data, but we should do this sparingly. For some categorical columns, you could set a default value, but I will not be doing this much. You cannot assume exactly what the person who entered the data intended by leaving it blank, and filling it could cause innacuracies, especially with columns with a lot of missing data. But for some columns, there is simply too much missing data. For this reason, I will be dropping all columns with more than 25% missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "COLUMNS_TO_REMOVE_MISSING_VALUES = missing_values[missing_values['percentage_missing'] > 0.25].index\n",
    "df_second_column_drop = df_first_column_drop.drop(columns=COLUMNS_TO_REMOVE_MISSING_VALUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "df_second_column_drop.to_csv('data_second_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's recheck the list of columns with missing data, and address each one indiviually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      missing_values  percentage_missing\n",
      "year_built_estimate            94314            0.187165\n",
      "depth                          34709            0.068880\n",
      "total_area                     32821            0.065133\n",
      "topography                     32339            0.064177\n",
      "general_construction           15954            0.031661\n",
      "garage_spaces                   8248            0.016368\n",
      "fireplaces                      6963            0.013818\n",
      "number_of_bathrooms             6665            0.013227\n",
      "off_street_open                 4751            0.009428\n",
      "number_of_bedrooms              3458            0.006862\n",
      "interior_condition              3339            0.006626\n",
      "number_stories                  3323            0.006594\n",
      "exterior_condition              3238            0.006426\n",
      "frontage                        3149            0.006249\n",
      "view_type                       2857            0.005670\n",
      "zoning                          1177            0.002336\n",
      "total_livable_area               852            0.001691\n",
      "year_built                       621            0.001232\n",
      "census_tract                      23            0.000046\n",
      "lat                               22            0.000044\n",
      "lng                               22            0.000044\n",
      "taxable_building                  20            0.000040\n",
      "taxable_land                      19            0.000038\n",
      "market_value                      19            0.000038\n",
      "exempt_land                       19            0.000038\n",
      "exempt_building                   19            0.000038\n"
     ]
    }
   ],
   "source": [
    "missing_values_2 = df_second_column_drop.isna().sum().sort_values(ascending=False)\n",
    "missing_values_2 = missing_values_2[missing_values_2 > 0]\n",
    "missing_values_2 = pd.DataFrame(missing_values_2, columns=['missing_values'])\n",
    "missing_values_2['percentage_missing'] = missing_values_2['missing_values'] / len(df_second_column_drop)\n",
    "print(missing_values_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are left with columns with most of their data filled in, it is much safter to start filling in with default or imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_fill = df_second_column_drop\n",
    "# year_built_estimate can be filled with N's\n",
    "df_fill['year_built_estimate'] = df_fill['year_built_estimate'].fillna('N')\n",
    "# garage_spaces can just be filled with 0. It is a fair assumption that if the value is missing, there is no garage\n",
    "df_fill['garage_spaces'] = df_fill['garage_spaces'].fillna(0)\n",
    "# fireplaces can just be filled with 0. It is a fair assumption that if the value is missing, there are no fireplaces\n",
    "df_fill['fireplaces'] = df_fill['fireplaces'].fillna(0)\n",
    "# number of bathrooms can be filled with the median\n",
    "df_fill['number_of_bathrooms'] = median_imputer.fit_transform(df_fill[['number_of_bathrooms']])\n",
    "# interior condition can be filled with the median\n",
    "df_fill['interior_condition'] = median_imputer.fit_transform(df_fill[['interior_condition']])\n",
    "# exterior condition can be filled with the median\n",
    "df_fill['exterior_condition'] = median_imputer.fit_transform(df_fill[['exterior_condition']])\n",
    "# number of bedrooms can be filled with the median\n",
    "df_fill['number_of_bedrooms'] = median_imputer.fit_transform(df_fill[['number_of_bedrooms']])\n",
    "# number of stories can be filled with the median\n",
    "df_fill['number_stories'] = median_imputer.fit_transform(df_fill[['number_stories']])\n",
    "# NOTE: Maybe change these to mode\n",
    "# general construction can be filled with a new category called 'unknown'\n",
    "df_fill['general_construction'] = df_fill['general_construction'].fillna('unknown')\n",
    "# quality grade will be skipped for now because it needs to be transformed into a numeric column\n",
    "# year built can be filled with the median\n",
    "df_fill['year_built'] = median_imputer.fit_transform(df_fill[['year_built']])\n",
    "# total livable area can be filled with the median\n",
    "df_fill['total_livable_area'] = median_imputer.fit_transform(df_fill[['total_livable_area']])\n",
    "# topography can be filled with a new category called 'unknown'\n",
    "df_fill['topography'] = df_fill['topography'].fillna('unknown')\n",
    "# depth can be filled with the median\n",
    "df_fill['depth'] = median_imputer.fit_transform(df_fill[['depth']])\n",
    "# total area can be filled with the median\n",
    "df_fill['total_area'] = median_imputer.fit_transform(df_fill[['total_area']])\n",
    "# view type can be filled with a new category called 'unknown'\n",
    "df_fill['view_type'] = df_fill['view_type'].fillna('unknown')\n",
    "# off street open can be filled with the median\n",
    "df_fill['off_street_open'] = median_imputer.fit_transform(df_fill[['off_street_open']])\n",
    "# frontage can be filled with the median\n",
    "df_fill['frontage'] = median_imputer.fit_transform(df_fill[['frontage']])\n",
    "# zoning can be filled with a new category called 'unknown'\n",
    "df_fill['zoning'] = df_fill['zoning'].fillna('unknown')\n",
    "# census tract can be filled with the median\n",
    "df_fill['census_tract'] = median_imputer.fit_transform(df_fill[['census_tract']])\n",
    "# lat and lng can be filled with the median\n",
    "df_fill['lat'] = median_imputer.fit_transform(df_fill[['lat']])\n",
    "df_fill['lng'] = median_imputer.fit_transform(df_fill[['lng']])\n",
    "# taxable building can be filled with the median\n",
    "df_fill['taxable_building'] = median_imputer.fit_transform(df_fill[['taxable_building']])\n",
    "# exempt land can be filled with the median\n",
    "df_fill['exempt_land'] = median_imputer.fit_transform(df_fill[['exempt_land']])\n",
    "# exempt building can be filled with the median\n",
    "df_fill['exempt_building'] = median_imputer.fit_transform(df_fill[['exempt_building']])\n",
    "# taxable land can be filled with the median\n",
    "df_fill['taxable_land'] = median_imputer.fit_transform(df_fill[['taxable_land']])\n",
    "# NOTE: Maybe change this to drop\n",
    "# market value can be filled with the median\n",
    "df_fill['market_value'] = median_imputer.fit_transform(df_fill[['market_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check again our missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [missing_values, percentage_missing]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "missing_values_3 = df_fill.isna().sum().sort_values(ascending=False)\n",
    "missing_values_3 = missing_values_3[missing_values_3 > 0]\n",
    "missing_values_3 = pd.DataFrame(missing_values_3, columns=['missing_values'])\n",
    "missing_values_3['percentage_missing'] = missing_values_3['missing_values'] / len(df_second_column_drop)\n",
    "print(missing_values_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df_fill.to_csv('data_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# One hot columns\n",
    "ONE_HOT_COLUMNS = [\n",
    "    'category_code',\n",
    "    'general_construction',\n",
    "    'topography',\n",
    "    'view_type',\n",
    "    'zoning',\n",
    "]\n",
    "\n",
    "BINARY_COLUMNS = [\n",
    "    'year_built_estimate',\n",
    "    'homestead_exemption',\n",
    "    'exempt_building',\n",
    "    'exempt_land'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24506/4010469351.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_one_hot['year_built_estimate'] = df_one_hot['year_built_estimate'].fillna(False)\n",
      "/tmp/ipykernel_24506/4010469351.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_one_hot['homestead_exemption'] = df_one_hot['homestead_exemption'].fillna(False)\n",
      "/tmp/ipykernel_24506/4010469351.py:13: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_one_hot['exempt_building'] = df_one_hot['exempt_building'].fillna(True)\n",
      "/tmp/ipykernel_24506/4010469351.py:17: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_one_hot['exempt_land'] = df_one_hot['exempt_land'].fillna(True)\n"
     ]
    }
   ],
   "source": [
    "# One hot encode the columns\n",
    "df_one_hot = pd.get_dummies(df_fill, columns=ONE_HOT_COLUMNS)\n",
    "# Binary encode the columns\n",
    "df_one_hot['year_built_estimate'] = df_one_hot['year_built_estimate'].map({'Y': True, 'N': False})\n",
    "# Fillna with False\n",
    "df_one_hot['year_built_estimate'] = df_one_hot['year_built_estimate'].fillna(False)\n",
    "df_one_hot['homestead_exemption'] = df_one_hot['homestead_exemption'].map({80000: True, 0: False})\n",
    "# Fillna with False\n",
    "df_one_hot['homestead_exemption'] = df_one_hot['homestead_exemption'].fillna(False)\n",
    "# Exempt building should be false if 0, else true\n",
    "df_one_hot['exempt_building'] = df_one_hot['exempt_building'].map({0: False})\n",
    "# Fillna with True\n",
    "df_one_hot['exempt_building'] = df_one_hot['exempt_building'].fillna(True)\n",
    "# Exempt land should be false if 0, else true\n",
    "df_one_hot['exempt_land'] = df_one_hot['exempt_land'].map({0.0: False})\n",
    "# Fillna with True\n",
    "df_one_hot['exempt_land'] = df_one_hot['exempt_land'].fillna(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool       78\n",
       "float64    19\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that all columns are numeric\n",
    "df_one_hot.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is a lot of boolean columns. We can probably drop some of these columns, but we will do that later. For now, we will just convert these columns to 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Get columns with type bool\n",
    "bool_columns = df_one_hot.select_dtypes(include=bool).columns\n",
    "# Change type of columns to int\n",
    "df_one_hot[bool_columns] = df_one_hot[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "# Delete outliers\n",
    "df_outliers = df_one_hot\n",
    "# Delete census_tract outliers\n",
    "#df_outliers = df_outliers[df_outliers['census_tract'] < 500]\n",
    "# Delete depth outliers < 200 and > 32\n",
    "df_outliers = df_outliers[df_outliers['depth'] < 144]\n",
    "df_outliers = df_outliers[df_outliers['depth'] > 32]\n",
    "# Fireplace < 6\n",
    "df_outliers = df_outliers[df_outliers['fireplaces'] < 6]\n",
    "# Frontage < 140\n",
    "df_outliers = df_outliers[df_outliers['frontage'] < 50]\n",
    "# Garage spaces < 5\n",
    "df_outliers = df_outliers[df_outliers['garage_spaces'] < 5]\n",
    "# Market value < 10_000_000\n",
    "df_outliers = df_outliers[df_outliers['market_value'] < 2_000_000]\n",
    "# Number of bathrooms < 6\n",
    "df_outliers = df_outliers[df_outliers['number_of_bathrooms'] < 6]\n",
    "# Number of bedrooms < 15\n",
    "df_outliers = df_outliers[df_outliers['number_of_bedrooms'] < 6]\n",
    "# Number of stories < 6\n",
    "df_outliers = df_outliers[df_outliers['number_stories'] < 6]\n",
    "# Taxable building < 4_000_000\n",
    "df_outliers = df_outliers[df_outliers['taxable_building'] < 1_000_000]\n",
    "# Taxable land < 1_000_000\n",
    "df_outliers = df_outliers[df_outliers['taxable_land'] < 200_000]\n",
    "# Total area < 250_000\n",
    "df_outliers = df_outliers[df_outliers['total_area'] < 16_000]\n",
    "# Total livable area < 250_000\n",
    "df_outliers = df_outliers[df_outliers['total_livable_area'] < 8_000]\n",
    "# Year built > 1840\n",
    "df_outliers = df_outliers[df_outliers['year_built'] > 1890]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(445963, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export to CSV excluding columns starting with ONE_HOT_COLUMNS\n",
    "df_out = df_outliers\n",
    "for column in ONE_HOT_COLUMNS:\n",
    "    df_out = df_out.loc[:, ~df_out.columns.str.startswith(column)]\n",
    "df_out.to_csv('data_outliers.csv', index=False)\n",
    "\n",
    "#df_outliers.to_csv('data_outliers.csv', index=False)\n",
    "df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "market_value           1.000000\n",
       "taxable_land           0.937928\n",
       "taxable_building       0.765416\n",
       "total_livable_area     0.517348\n",
       "year_built             0.340224\n",
       "total_area             0.180573\n",
       "number_stories         0.180235\n",
       "fireplaces             0.148861\n",
       "number_of_bathrooms    0.148615\n",
       "exempt_building        0.144842\n",
       "homestead_exemption    0.113693\n",
       "garage_spaces          0.107790\n",
       "depth                  0.088641\n",
       "frontage               0.087172\n",
       "lng                    0.038749\n",
       "off_street_open       -0.049713\n",
       "number_of_bedrooms    -0.119201\n",
       "lat                   -0.128467\n",
       "census_tract          -0.138953\n",
       "year_built_estimate   -0.174337\n",
       "exempt_land           -0.252257\n",
       "exterior_condition    -0.423758\n",
       "interior_condition    -0.456576\n",
       "Name: market_value, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a correlation graphic agains the market value\n",
    "correlation = df_out.corr()\n",
    "# Print the correlation with the target variable\n",
    "correlation['market_value'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that preprocessing is complete, we can move on to feature engineering. For this step we will be applying PCA to the data. With PCA, we will be having it reduce the dimension so that we retain 95% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_outliers), columns=df_outliers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "X = df_scaled.drop(columns='market_value')\n",
    "y = df_scaled['market_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445963, 96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(445963, 56)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA_VARIANCE = 0.8\n",
    "# Create a PCA instance\n",
    "pca = PCA(PCA_VARIANCE)\n",
    "pca.fit(X)\n",
    "# Transform the data\n",
    "X_pca = pca.transform(X)\n",
    "print(X.shape)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-11 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-11 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-11 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-11 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-11 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-11 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-11 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-11 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-11 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-11 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9512293454070778"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score the model\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361307053062926"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_model = LinearRegression()\n",
    "pca_model.fit(X_pca_train, y_pca_train)\n",
    "pca_model.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9818018612946061"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a decision tree model\n",
    "tree_model = DecisionTreeRegressor()\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902814734126171"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random forest model\n",
    "forest_model = RandomForestRegressor()\n",
    "forest_model.fit(X_train, y_train)\n",
    "forest_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9002268095787773"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a decision tree model with PCA\n",
    "pca_tree_model = DecisionTreeRegressor()\n",
    "pca_tree_model.fit(X_pca_train, y_pca_train)\n",
    "pca_tree_model.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_pca_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create a random forest model with PCA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pca_forest_model \u001b[39m=\u001b[39m RandomForestRegressor()\n\u001b[0;32m----> 3\u001b[0m pca_forest_model\u001b[39m.\u001b[39mfit(X_pca_train, y_pca_train)\n\u001b[1;32m      4\u001b[0m pca_forest_model\u001b[39m.\u001b[39mscore(X_pca_test, y_pca_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_pca_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a random forest model with PCA\n",
    "# pca_forest_model = RandomForestRegressor()\n",
    "# pca_forest_model.fit(X_pca_train, y_pca_train)\n",
    "# pca_forest_model.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.978827266418655"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a gradient boosting model\n",
    "gradient_model = GradientBoostingRegressor()\n",
    "gradient_model.fit(X_train, y_train)\n",
    "gradient_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8904228428584422"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a gradient boosting model with PCA\n",
    "pca_gradient_model = GradientBoostingRegressor()\n",
    "pca_gradient_model.fit(X_pca_train, y_pca_train)\n",
    "pca_gradient_model.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927289109991099"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model with xgboost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518887683463301"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model with xgboost with PCA\n",
    "pca_xgb_model = xgb.XGBRegressor()\n",
    "pca_xgb_model.fit(X_pca_train, y_pca_train)\n",
    "pca_xgb_model.score(X_pca_test, y_pca_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Save all of the models\n",
    "import pickle\n",
    "pickle.dump(model, open('linear_model.pkl', 'wb'))\n",
    "pickle.dump(tree_model, open('tree_model.pkl', 'wb'))\n",
    "pickle.dump(forest_model, open('forest_model.pkl', 'wb'))\n",
    "pickle.dump(gradient_model, open('gradient_model.pkl', 'wb'))\n",
    "pickle.dump(xgb_model, open('xgb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pca_model, open(f'pca_{PCA_VARIANCE}_linear_model.pkl', 'wb'))\n",
    "pickle.dump(pca_tree_model, open(f'pca_{PCA_VARIANCE}_tree_model.pkl', 'wb'))\n",
    "pickle.dump(pca_forest_model, open(f'pca_{PCA_VARIANCE}_forest_model.pkl', 'wb'))\n",
    "pickle.dump(pca_gradient_model, open(f'pca_{PCA_VARIANCE}_gradient_model.pkl', 'wb'))\n",
    "pickle.dump(pca_xgb_model, open(f'pca_{PCA_VARIANCE}_xgb_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'n_components' parameter of PCA must be an int in the range [0, inf), a float in the range (0.0, 1.0), a str among {'mle'} or None. Got 1.0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m scores\u001b[39m.\u001b[39mloc[variance, \u001b[39m\"\u001b[39m\u001b[39mvariance\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m variance\n\u001b[1;32m     12\u001b[0m pca \u001b[39m=\u001b[39m PCA(variance)\n\u001b[0;32m---> 13\u001b[0m pca\u001b[39m.\u001b[39;49mfit(X)\n\u001b[1;32m     14\u001b[0m X_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m     15\u001b[0m X_pca_train, X_pca_test, y_pca_train, y_pca_test \u001b[39m=\u001b[39m train_test_split(X_pca, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n",
      "File \u001b[0;32m~/CMPSC-445-Project1/venv/lib/python3.11/site-packages/sklearn/base.py:1467\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1463\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1464\u001b[0m )\n\u001b[1;32m   1466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1467\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[1;32m   1474\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/CMPSC-445-Project1/venv/lib/python3.11/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    659\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \n\u001b[1;32m    661\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    667\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[1;32m    668\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    669\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    670\u001b[0m     )\n",
      "File \u001b[0;32m~/CMPSC-445-Project1/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'n_components' parameter of PCA must be an int in the range [0, inf), a float in the range (0.0, 1.0), a str among {'mle'} or None. Got 1.0 instead."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import logging\n",
    "logging.basicConfig(filename='pca.log', level=logging.INFO, format=\"%(asctime)s:%(levelname)s:%(message)s\")\n",
    "scores = pd.DataFrame(columns=[\"variance\", \"linear\", \"tree\", \"forest\", \"gradient\", \"xgb\"])\n",
    "# scores: variance, linear, tree, forest, gradient, xgb\n",
    "scores.set_index(\"variance\", inplace=True)\n",
    "for n in range(10, 11):\n",
    "    variance = n / 10\n",
    "    logging.info(f\"{variance=}\")\n",
    "    scores.loc[variance, \"variance\"] = variance\n",
    "    pca = PCA(variance)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    X_pca_train, X_pca_test, y_pca_train, y_pca_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "    pca_model = LinearRegression()\n",
    "    pca_model.fit(X_pca_train, y_pca_train)\n",
    "    logging.info(f\"{pca_model.score(X_pca_test, y_pca_test)=}\")\n",
    "    scores.loc[variance, \"linear\"] = pca_model.score(X_pca_test, y_pca_test)\n",
    "    pca_tree_model = DecisionTreeRegressor()\n",
    "    pca_tree_model.fit(X_pca_train, y_pca_train)\n",
    "    logging.info(f\"{pca_tree_model.score(X_pca_test, y_pca_test)=}\")\n",
    "    scores.loc[variance, \"tree\"] = pca_tree_model.score(X_pca_test, y_pca_test)\n",
    "    pca_forest_model = RandomForestRegressor()\n",
    "    pca_forest_model.fit(X_pca_train, y_pca_train)\n",
    "    logging.info(f\"{pca_forest_model.score(X_pca_test, y_pca_test)=}\")\n",
    "    scores.loc[variance, \"forest\"] = pca_forest_model.score(X_pca_test, y_pca_test)\n",
    "    pca_gradient_model = GradientBoostingRegressor()\n",
    "    pca_gradient_model.fit(X_pca_train, y_pca_train)\n",
    "    logging.info(f\"{pca_gradient_model.score(X_pca_test, y_pca_test)=}\")\n",
    "    scores.loc[variance, \"gradient\"] = pca_gradient_model.score(X_pca_test, y_pca_test)\n",
    "    pca_xgb_model = xgb.XGBRegressor()\n",
    "    pca_xgb_model.fit(X_pca_train, y_pca_train)\n",
    "    logging.info(f\"{pca_xgb_model.score(X_pca_test, y_pca_test)=}\")\n",
    "    scores.loc[variance, \"xgb\"] = pca_xgb_model.score(X_pca_test, y_pca_test)\n",
    "    scores.to_csv(\"scores.csv\", index=\"variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc6db4e0d53691edb177bb7f02452d6efa438b9e20a1af03e9281c2ab8183f1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
