{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install dependencies and download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt\n",
    "#!curl -l -o data.csv \"https://phl.carto.com/api/v2/sql?q=SELECT+*,+ST_Y(the_geom)+AS+lat,+ST_X(the_geom)+AS+lng+FROM+opa_properties_public&filename=opa_properties_public&format=csv&skipfields=cartodb_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6262/1507164070.py:1: DtypeWarning: Columns (5,13,22,26,31,54,55,68,70,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the_geom</th>\n",
       "      <th>the_geom_webmercator</th>\n",
       "      <th>assessment_date</th>\n",
       "      <th>basements</th>\n",
       "      <th>beginning_point</th>\n",
       "      <th>book_and_page</th>\n",
       "      <th>building_code</th>\n",
       "      <th>building_code_description</th>\n",
       "      <th>category_code</th>\n",
       "      <th>category_code_description</th>\n",
       "      <th>...</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_built_estimate</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>zoning</th>\n",
       "      <th>pin</th>\n",
       "      <th>building_code_new</th>\n",
       "      <th>building_code_description_new</th>\n",
       "      <th>objectid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0101000020E6100000288FB7AD4BC452C0C6E4F1E75A01...</td>\n",
       "      <td>0101000020110F00002693FA5D94E05FC1EE7D5D356691...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120' NW EADOM ST</td>\n",
       "      <td>987458.0</td>\n",
       "      <td>RB</td>\n",
       "      <td>NON PD PKG LOT COMMERCIAL</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19137.0</td>\n",
       "      <td>IRMX</td>\n",
       "      <td>1001189957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143301</td>\n",
       "      <td>40.010587</td>\n",
       "      <td>-75.067119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101000020E610000015F6916732CB52C0D4B37C0242FE...</td>\n",
       "      <td>0101000020110F0000F30438544DEC5FC1AAE24928F78D...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273' N OF NORRIS ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SR</td>\n",
       "      <td>VACANT LAND RESIDE &lt; ACRE</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19121.0</td>\n",
       "      <td>RSA5</td>\n",
       "      <td>1001505175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143302</td>\n",
       "      <td>39.986389</td>\n",
       "      <td>-75.174951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0101000020E610000066AC299B48CA52C053CA1DF46CFD...</td>\n",
       "      <td>0101000020110F00004ACDE132C0EA5FC17F6F06010B8D...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>263' 8\" N COLUMBIA AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U50</td>\n",
       "      <td>ROW CONV/APT 3 STY MASON</td>\n",
       "      <td>2</td>\n",
       "      <td>MULTI FAMILY</td>\n",
       "      <td>...</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19121.0</td>\n",
       "      <td>RM1</td>\n",
       "      <td>1001622123</td>\n",
       "      <td>22</td>\n",
       "      <td>ROW TYPICAL</td>\n",
       "      <td>433143303</td>\n",
       "      <td>39.979887</td>\n",
       "      <td>-75.160682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0101000020E6100000000000000000F87F000000000000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,115.962' S PATTISON AVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>VACANT LAND RESIDE ACRE+</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001319180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0101000020E61000000C5CFE385BC452C0E38B05E75601...</td>\n",
       "      <td>0101000020110F0000F7332EC5AEE05FC1240EE0C46191...</td>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEC SCATTERGOOD TO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RB</td>\n",
       "      <td>NON PD PKG LOT COMMERCIAL</td>\n",
       "      <td>6</td>\n",
       "      <td>VACANT LAND</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19137.0</td>\n",
       "      <td>IRMX</td>\n",
       "      <td>1001189938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433143305</td>\n",
       "      <td>40.010465</td>\n",
       "      <td>-75.068068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            the_geom  \\\n",
       "0  0101000020E6100000288FB7AD4BC452C0C6E4F1E75A01...   \n",
       "1  0101000020E610000015F6916732CB52C0D4B37C0242FE...   \n",
       "2  0101000020E610000066AC299B48CA52C053CA1DF46CFD...   \n",
       "3  0101000020E6100000000000000000F87F000000000000...   \n",
       "4  0101000020E61000000C5CFE385BC452C0E38B05E75601...   \n",
       "\n",
       "                                the_geom_webmercator assessment_date  \\\n",
       "0  0101000020110F00002693FA5D94E05FC1EE7D5D356691...      2022-05-24   \n",
       "1  0101000020110F0000F30438544DEC5FC1AAE24928F78D...      2022-05-24   \n",
       "2  0101000020110F00004ACDE132C0EA5FC17F6F06010B8D...      2022-05-24   \n",
       "3                                                NaN      2022-05-24   \n",
       "4  0101000020110F0000F7332EC5AEE05FC1240EE0C46191...      2022-05-24   \n",
       "\n",
       "  basements            beginning_point book_and_page building_code  \\\n",
       "0       NaN           120' NW EADOM ST      987458.0         RB      \n",
       "1       NaN        273' N OF NORRIS ST           NaN         SR      \n",
       "2       NaN     263' 8\" N COLUMBIA AVE           NaN         U50     \n",
       "3       NaN  1,115.962' S PATTISON AVE           NaN         SS      \n",
       "4       NaN         NEC SCATTERGOOD TO           NaN         RB      \n",
       "\n",
       "   building_code_description  category_code category_code_description  ...  \\\n",
       "0  NON PD PKG LOT COMMERCIAL              6               VACANT LAND  ...   \n",
       "1  VACANT LAND RESIDE < ACRE              6               VACANT LAND  ...   \n",
       "2   ROW CONV/APT 3 STY MASON              2              MULTI FAMILY  ...   \n",
       "3   VACANT LAND RESIDE ACRE+              6               VACANT LAND  ...   \n",
       "4  NON PD PKG LOT COMMERCIAL              6               VACANT LAND  ...   \n",
       "\n",
       "   year_built year_built_estimate  zip_code zoning         pin  \\\n",
       "0         NaN                 NaN   19137.0   IRMX  1001189957   \n",
       "1         NaN                 NaN   19121.0   RSA5  1001505175   \n",
       "2      1890.0                 NaN   19121.0    RM1  1001622123   \n",
       "3         NaN                 NaN       NaN    NaN  1001319180   \n",
       "4         NaN                 NaN   19137.0   IRMX  1001189938   \n",
       "\n",
       "   building_code_new  building_code_description_new   objectid        lat  \\\n",
       "0                NaN                            NaN  433143301  40.010587   \n",
       "1                NaN                            NaN  433143302  39.986389   \n",
       "2                 22                    ROW TYPICAL  433143303  39.979887   \n",
       "3                NaN                            NaN  433143304        NaN   \n",
       "4                NaN                            NaN  433143305  40.010465   \n",
       "\n",
       "         lng  \n",
       "0 -75.067119  \n",
       "1 -75.174951  \n",
       "2 -75.160682  \n",
       "3        NaN  \n",
       "4 -75.068068  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['the_geom', 'the_geom_webmercator', 'assessment_date', 'basements',\n",
       "       'beginning_point', 'book_and_page', 'building_code',\n",
       "       'building_code_description', 'category_code',\n",
       "       'category_code_description', 'census_tract', 'central_air',\n",
       "       'cross_reference', 'date_exterior_condition', 'depth',\n",
       "       'exempt_building', 'exempt_land', 'exterior_condition', 'fireplaces',\n",
       "       'frontage', 'fuel', 'garage_spaces', 'garage_type',\n",
       "       'general_construction', 'geographic_ward', 'homestead_exemption',\n",
       "       'house_extension', 'house_number', 'interior_condition', 'location',\n",
       "       'mailing_address_1', 'mailing_address_2', 'mailing_care_of',\n",
       "       'mailing_city_state', 'mailing_street', 'mailing_zip', 'market_value',\n",
       "       'market_value_date', 'number_of_bathrooms', 'number_of_bedrooms',\n",
       "       'number_of_rooms', 'number_stories', 'off_street_open',\n",
       "       'other_building', 'owner_1', 'owner_2', 'parcel_number', 'parcel_shape',\n",
       "       'quality_grade', 'recording_date', 'registry_number', 'sale_date',\n",
       "       'sale_price', 'separate_utilities', 'sewer', 'site_type', 'state_code',\n",
       "       'street_code', 'street_designation', 'street_direction', 'street_name',\n",
       "       'suffix', 'taxable_building', 'taxable_land', 'topography',\n",
       "       'total_area', 'total_livable_area', 'type_heater', 'unfinished', 'unit',\n",
       "       'utility', 'view_type', 'year_built', 'year_built_estimate', 'zip_code',\n",
       "       'zoning', 'pin', 'building_code_new', 'building_code_description_new',\n",
       "       'objectid', 'lat', 'lng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see all of the columns available in the dataset. Many of these columns are not really necesary. For example, geographical data such as street addresses are not very useful because they don't contain any categorical or numerical data that can be easily consumed by a linear regression mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_REMOVE = \"\"\"\n",
    "the_geom\n",
    "the_geom_webmercator\n",
    "beginning_point\n",
    "book_and_page\n",
    "building_code_description\n",
    "category_code_description\n",
    "cross_reference\n",
    "geographic_ward\n",
    "house_number\n",
    "location\n",
    "mailing_address_1\n",
    "mailing_address_2\n",
    "mailing_care_of\n",
    "mailing_city_state\n",
    "mailing_street\n",
    "mailing_zip\n",
    "other_building\n",
    "owner_1\n",
    "owner_2\n",
    "parcel_number\n",
    "registry_number\n",
    "state_code\n",
    "street_code\n",
    "street_designation\n",
    "street_direction\n",
    "street_name\n",
    "suffix\n",
    "pin\n",
    "building_code_description_new\n",
    "objectid\n",
    "unit\n",
    "\"\"\"\n",
    "df_first_column_drop = df.drop(columns=COLUMNS_TO_REMOVE.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_column_drop.to_csv('data_first_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have removed some of the columns, lets see what we are left with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assessment_date             object\n",
       "basements                   object\n",
       "building_code               object\n",
       "category_code                int64\n",
       "census_tract               float64\n",
       "central_air                 object\n",
       "date_exterior_condition     object\n",
       "depth                      float64\n",
       "exempt_building            float64\n",
       "exempt_land                float64\n",
       "exterior_condition         float64\n",
       "fireplaces                 float64\n",
       "frontage                   float64\n",
       "fuel                        object\n",
       "garage_spaces              float64\n",
       "garage_type                 object\n",
       "general_construction        object\n",
       "homestead_exemption          int64\n",
       "house_extension             object\n",
       "interior_condition         float64\n",
       "market_value               float64\n",
       "market_value_date          float64\n",
       "number_of_bathrooms        float64\n",
       "number_of_bedrooms         float64\n",
       "number_of_rooms            float64\n",
       "number_stories             float64\n",
       "off_street_open            float64\n",
       "parcel_shape                object\n",
       "quality_grade               object\n",
       "recording_date              object\n",
       "sale_date                   object\n",
       "sale_price                 float64\n",
       "separate_utilities          object\n",
       "sewer                       object\n",
       "site_type                   object\n",
       "taxable_building           float64\n",
       "taxable_land               float64\n",
       "topography                  object\n",
       "total_area                 float64\n",
       "total_livable_area         float64\n",
       "type_heater                 object\n",
       "unfinished                  object\n",
       "utility                     object\n",
       "view_type                   object\n",
       "year_built                 float64\n",
       "year_built_estimate         object\n",
       "zip_code                   float64\n",
       "zoning                      object\n",
       "building_code_new           object\n",
       "lat                        float64\n",
       "lng                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first_column_drop.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do some digging into these 1 by 1. To start, I will start grouping the features into a few different types:\n",
    "- DateTime\n",
    "- Categorical\n",
    "- Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATETIME_COLUMNS = \"\"\"\n",
    "assessment_date\n",
    "date_exterior_condition\n",
    "market_value_date\n",
    "recording_date\n",
    "sale_date\n",
    "year_built\n",
    "market_value_date\n",
    "sale_date\n",
    "\"\"\"\n",
    "\n",
    "CATEGORICAL_COLUMNS = \"\"\"\n",
    "basements\n",
    "building_code\n",
    "category_code\n",
    "central_air\n",
    "fuel\n",
    "general_construction\n",
    "garage_type\n",
    "other_building\n",
    "parcel_shape\n",
    "quality_grade\n",
    "separate_utilities\n",
    "sewer\n",
    "site_type\n",
    "street_direction\n",
    "topography\n",
    "type_heater\n",
    "unfinished\n",
    "utility\n",
    "view_type\n",
    "year_built_estimate\n",
    "zip_code\n",
    "zoning\n",
    "building_code_new\n",
    "\"\"\"\n",
    "\n",
    "NUMERIC_COLUMNS = \"\"\"\n",
    "census_tract\n",
    "depth\n",
    "exempt_building\n",
    "exempt_land\n",
    "exterior_condition\n",
    "fireplaces\n",
    "frontage\n",
    "garage_spaces\n",
    "homestead_exemption\n",
    "house_extension\n",
    "interior_condition\n",
    "number_of_bathrooms\n",
    "number_of_bedrooms\n",
    "number_of_rooms\n",
    "number_stories\n",
    "market_value\n",
    "off_street_open\n",
    "taxable_building\n",
    "taxable_land\n",
    "total_area\n",
    "total_livable_area\n",
    "sale_price\n",
    "lat\n",
    "lng\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a lot of columns. It is very likely that many more of these will get dropped for the following reasons:\n",
    "1. Too many missing values\n",
    "2. Too many unique values\n",
    "3. Not enough correlation with the target variable\n",
    "\n",
    "Let's start by dealing with the first case: too many missing values. We will check this by counting the number of missing values in each column and sorting by this number.\n",
    "\n",
    "There are also a few columns that seem to have a default value put in them instead of being left blank. Lets also change these default values to na, so they can be counted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_column_drop['depth'] = df_first_column_drop['depth'].replace(0, np.nan)\n",
    "df_first_column_drop['total_area'] = df_first_column_drop['total_area'].replace(0, np.nan)\n",
    "df_first_column_drop['total_livable_area'] = df_first_column_drop['total_livable_area'].replace(0, np.nan)\n",
    "df_first_column_drop['year_built'] = df_first_column_drop['year_built'].replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         missing_values  percentage_missing\n",
      "market_value_date                582937            1.000000\n",
      "unfinished                       582866            0.999878\n",
      "utility                          582774            0.999720\n",
      "site_type                        580454            0.995741\n",
      "date_exterior_condition          580279            0.995440\n",
      "sewer                            568010            0.974393\n",
      "number_of_rooms                  567929            0.974255\n",
      "garage_type                      560331            0.961221\n",
      "house_extension                  556640            0.954889\n",
      "separate_utilities               554744            0.951636\n",
      "fuel                             535365            0.918393\n",
      "central_air                      289516            0.496651\n",
      "type_heater                      282172            0.484052\n",
      "basements                        252910            0.433855\n",
      "year_built_estimate              171840            0.294783\n",
      "garage_spaces                     84805            0.145479\n",
      "fireplaces                        83568            0.143357\n",
      "number_of_bathrooms               83271            0.142847\n",
      "interior_condition                80264            0.137689\n",
      "exterior_condition                80101            0.137409\n",
      "number_of_bedrooms                80025            0.137279\n",
      "number_stories                    79827            0.136939\n",
      "general_construction              60330            0.103493\n",
      "quality_grade                     56108            0.096251\n",
      "building_code_new                 45781            0.078535\n",
      "year_built                        44381            0.076133\n",
      "total_livable_area                44058            0.075579\n",
      "topography                        38311            0.065721\n",
      "depth                             36853            0.063220\n",
      "total_area                        34376            0.058970\n",
      "view_type                         20623            0.035378\n",
      "off_street_open                    7514            0.012890\n",
      "assessment_date                    4920            0.008440\n",
      "frontage                           4054            0.006954\n",
      "recording_date                     3775            0.006476\n",
      "parcel_shape                       2866            0.004916\n",
      "sale_price                         2506            0.004299\n",
      "sale_date                          2485            0.004263\n",
      "zoning                             2357            0.004043\n",
      "census_tract                        139            0.000238\n",
      "zip_code                            136            0.000233\n",
      "lat                                 135            0.000232\n",
      "lng                                 135            0.000232\n",
      "building_code                        60            0.000103\n",
      "taxable_building                     21            0.000036\n",
      "exempt_building                      20            0.000034\n",
      "market_value                         20            0.000034\n",
      "taxable_land                         20            0.000034\n",
      "exempt_land                          20            0.000034\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We still have a lot of columns. It is very likely that many more of these will get dropped for the following reasons:\n",
    "1. Too many missing values\n",
    "2. Too many unique values\n",
    "3. Not enough correlation with the target variable\n",
    "\n",
    "Let's start by dealing withe the first case: too many missing values. We will check this by counting the number of missing values in each column and sorting by this number.\n",
    "\"\"\"\n",
    "#print(df_first_column_drop.isna().sum().sort_values(ascending=False))\n",
    "# Print the number of missing values and the percentage of missing values\n",
    "missing_values = df_first_column_drop.isna().sum().sort_values(ascending=False)\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "missing_values = pd.DataFrame(missing_values, columns=['missing_values'])\n",
    "missing_values['percentage_missing'] = missing_values['missing_values'] / len(df_first_column_drop)\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some of these pieces of missing data won't be that big of a deal because we can either fill or impute the data. We can also drop rows with missing data, but we should do this sparingly. For some categorical columns, you could set a default value, but I will not be doing this much. You cannot assume exactly what the person who entered the data intended by leaving it blank, and filling it could cause innacuracies, especially with columns with a lot of missing data. But for some columns, there is simply too much missing data. For this reason, I will be dropping all columns with more than 25% missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_REMOVE_MISSING_VALUES = missing_values[missing_values['percentage_missing'] > 0.25].index\n",
    "df_second_column_drop = df_first_column_drop.drop(columns=COLUMNS_TO_REMOVE_MISSING_VALUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_column_drop.to_csv('data_second_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's recheck the list of columns with missing data, and address each one indiviually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      missing_values  percentage_missing\n",
      "garage_spaces                  84805            0.145479\n",
      "fireplaces                     83568            0.143357\n",
      "number_of_bathrooms            83271            0.142847\n",
      "interior_condition             80264            0.137689\n",
      "exterior_condition             80101            0.137409\n",
      "number_of_bedrooms             80025            0.137279\n",
      "number_stories                 79827            0.136939\n",
      "general_construction           60330            0.103493\n",
      "quality_grade                  56108            0.096251\n",
      "building_code_new              45781            0.078535\n",
      "year_built                     44381            0.076133\n",
      "total_livable_area             44058            0.075579\n",
      "topography                     38311            0.065721\n",
      "depth                          36853            0.063220\n",
      "total_area                     34376            0.058970\n",
      "view_type                      20623            0.035378\n",
      "off_street_open                 7514            0.012890\n",
      "assessment_date                 4920            0.008440\n",
      "frontage                        4054            0.006954\n",
      "recording_date                  3775            0.006476\n",
      "parcel_shape                    2866            0.004916\n",
      "sale_price                      2506            0.004299\n",
      "sale_date                       2485            0.004263\n",
      "zoning                          2357            0.004043\n",
      "census_tract                     139            0.000238\n",
      "zip_code                         136            0.000233\n",
      "lat                              135            0.000232\n",
      "lng                              135            0.000232\n",
      "building_code                     60            0.000103\n",
      "taxable_building                  21            0.000036\n",
      "exempt_land                       20            0.000034\n",
      "exempt_building                   20            0.000034\n",
      "taxable_land                      20            0.000034\n",
      "market_value                      20            0.000034\n"
     ]
    }
   ],
   "source": [
    "missing_values_2 = df_second_column_drop.isna().sum().sort_values(ascending=False)\n",
    "missing_values_2 = missing_values_2[missing_values_2 > 0]\n",
    "missing_values_2 = pd.DataFrame(missing_values_2, columns=['missing_values'])\n",
    "missing_values_2['percentage_missing'] = missing_values_2['missing_values'] / len(df_second_column_drop)\n",
    "print(missing_values_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are left with columns with most of their data filled in, it is much safter to start filling in with default or imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_fill = df_second_column_drop\n",
    "# garage_spaces can just be filled with 0. It is a fair assumption that if the value is missing, there is no garage\n",
    "df_fill['garage_spaces'] = df_fill['garage_spaces'].fillna(0)\n",
    "# fireplaces can just be filled with 0. It is a fair assumption that if the value is missing, there are no fireplaces\n",
    "df_fill['fireplaces'] = df_fill['fireplaces'].fillna(0)\n",
    "# number of bathrooms can be filled with the median\n",
    "df_fill['number_of_bathrooms'] = median_imputer.fit_transform(df_fill[['number_of_bathrooms']])\n",
    "# interior condition can be filled with the median\n",
    "df_fill['interior_condition'] = median_imputer.fit_transform(df_fill[['interior_condition']])\n",
    "# exterior condition can be filled with the median\n",
    "df_fill['exterior_condition'] = median_imputer.fit_transform(df_fill[['exterior_condition']])\n",
    "# number of bedrooms can be filled with the median\n",
    "df_fill['number_of_bedrooms'] = median_imputer.fit_transform(df_fill[['number_of_bedrooms']])\n",
    "# number of stories can be filled with the median\n",
    "df_fill['number_stories'] = median_imputer.fit_transform(df_fill[['number_stories']])\n",
    "# NOTE: Maybe change these to mode\n",
    "# general construction can be filled with a new category called 'unknown'\n",
    "df_fill['general_construction'] = df_fill['general_construction'].fillna('unknown')\n",
    "# quality grade will be skipped for now because it needs to be transformed into a numeric column\n",
    "# building code new can be filled with a new category called 'unknown'\n",
    "df_fill['building_code_new'] = df_fill['building_code_new'].fillna('unknown')\n",
    "# year built can be filled with the median\n",
    "df_fill['year_built'] = median_imputer.fit_transform(df_fill[['year_built']])\n",
    "# total livable area can be filled with the median\n",
    "df_fill['total_livable_area'] = median_imputer.fit_transform(df_fill[['total_livable_area']])\n",
    "# topography can be filled with a new category called 'unknown'\n",
    "df_fill['topography'] = df_fill['topography'].fillna('unknown')\n",
    "# depth can be filled with the median\n",
    "df_fill['depth'] = median_imputer.fit_transform(df_fill[['depth']])\n",
    "# total area can be filled with the median\n",
    "df_fill['total_area'] = median_imputer.fit_transform(df_fill[['total_area']])\n",
    "# view type can be filled with a new category called 'unknown'\n",
    "df_fill['view_type'] = df_fill['view_type'].fillna('unknown')\n",
    "# off street open can be filled with the median\n",
    "df_fill['off_street_open'] = median_imputer.fit_transform(df_fill[['off_street_open']])\n",
    "# assessment date will be skipped for now because it needs to be transformed into a numeric column\n",
    "# frontage can be filled with the median\n",
    "df_fill['frontage'] = median_imputer.fit_transform(df_fill[['frontage']])\n",
    "# recording date will be skipped for now because it needs to be transformed into a numeric column\n",
    "# parcel shape can be filled with a new category called 'unknown'\n",
    "df_fill['parcel_shape'] = df_fill['parcel_shape'].fillna('unknown')\n",
    "# NOTE: Maybe change this to drop\n",
    "# sale price can be filled with the median\n",
    "df_fill['sale_price'] = median_imputer.fit_transform(df_fill[['sale_price']])\n",
    "# sale date will be skipped for now because it needs to be transformed into a numeric column\n",
    "# zoning can be filled with a new category called 'unknown'\n",
    "df_fill['zoning'] = df_fill['zoning'].fillna('unknown')\n",
    "# census tract can be filled with the median\n",
    "df_fill['census_tract'] = median_imputer.fit_transform(df_fill[['census_tract']])\n",
    "# NOTE: Maybe change this to mode\n",
    "# zip code can be filled with a new category called 'unknown'\n",
    "df_fill['zip_code'] = df_fill['zip_code'].fillna('unknown')\n",
    "# lat and lng can be filled with the median\n",
    "df_fill['lat'] = median_imputer.fit_transform(df_fill[['lat']])\n",
    "df_fill['lng'] = median_imputer.fit_transform(df_fill[['lng']])\n",
    "# building code can be filled with a new category called 'unknown'\n",
    "df_fill['building_code'] = df_fill['building_code'].fillna('unknown')\n",
    "# taxable building can be filled with the median\n",
    "df_fill['taxable_building'] = median_imputer.fit_transform(df_fill[['taxable_building']])\n",
    "# exempt land can be filled with the median\n",
    "df_fill['exempt_land'] = median_imputer.fit_transform(df_fill[['exempt_land']])\n",
    "# exempt building can be filled with the median\n",
    "df_fill['exempt_building'] = median_imputer.fit_transform(df_fill[['exempt_building']])\n",
    "# taxable land can be filled with the median\n",
    "df_fill['taxable_land'] = median_imputer.fit_transform(df_fill[['taxable_land']])\n",
    "# NOTE: Maybe change this to drop\n",
    "# market value can be filled with the median\n",
    "df_fill['market_value'] = median_imputer.fit_transform(df_fill[['market_value']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check again our missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 missing_values  percentage_missing\n",
      "quality_grade             56108            0.096251\n",
      "assessment_date            4920            0.008440\n",
      "recording_date             3775            0.006476\n",
      "sale_date                  2485            0.004263\n"
     ]
    }
   ],
   "source": [
    "missing_values_3 = df_fill.isna().sum().sort_values(ascending=False)\n",
    "missing_values_3 = missing_values_3[missing_values_3 > 0]\n",
    "missing_values_3 = pd.DataFrame(missing_values_3, columns=['missing_values'])\n",
    "missing_values_3['percentage_missing'] = missing_values_3['missing_values'] / len(df_second_column_drop)\n",
    "print(missing_values_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we still need to get rid of the missing data for the date information by first converting them to datetimes, then either imputing or dropping NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date_fix = df_fill\n",
    "# Error from pandas: Out of bounds nanosecond timestamp: 3033-03-03, at position 49425. \n",
    "# This is likely a typo. Rather than fixing it, we will just drop the row, so as not to assume the correct date.\n",
    "df_date_fix = df_date_fix.drop(index=49425)\n",
    "\n",
    "df_date_fix['assessment_date'] = pd.to_datetime(df_date_fix['assessment_date'])\n",
    "df_date_fix['recording_date'] = pd.to_datetime(df_date_fix['recording_date'])\n",
    "df_date_fix['sale_date'] = pd.to_datetime(df_date_fix['sale_date'])\n",
    "\n",
    "# Then we can convert these columns to numeric\n",
    "df_date_fix['assessment_date'] = df_date_fix['assessment_date'].astype(int)\n",
    "df_date_fix['recording_date'] = df_date_fix['recording_date'].astype(int)\n",
    "df_date_fix['sale_date'] = df_date_fix['sale_date'].astype(int)\n",
    "\n",
    "# Now we can fill the missing values\n",
    "df_date_fix['assessment_date'] = median_imputer.fit_transform(df_date_fix[['assessment_date']])\n",
    "df_date_fix['recording_date'] = median_imputer.fit_transform(df_date_fix[['recording_date']])\n",
    "df_date_fix['sale_date'] = median_imputer.fit_transform(df_date_fix[['sale_date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
